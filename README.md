# Credit-Card-Fraud-Detection
Recognize fraudulent credit card transactions.

# Problem Statement:

The Credit Card Fraud Detection Problem includes modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. This model is then used to identify whether a new transaction is fraudulent or not. Our aim here is to detect 100% of the fraudulent transactions while minimizing the incorrect fraud classifications.

# How Does Credit Card Fraud Happen?
Credit card fraud is usually caused either by card owner’s negligence with his data or by a breach in a website’s security. Here are some examples:

A consumer reveals his credit card number to unfamiliar individuals.
A card is lost or stolen and someone else uses it.
Mail is stolen from the intended recipient and used by criminals.
Business employees copy cards or card numbers of its owner.
Making counterfeit credit cards

# Prerequisites
You just need Python 3.0+ or Jupyter Notebook installed in your local machine or you can open the project in Google Colab.

Install Python: https://www.python.org/downloads/

Install Jupyter Notebook:- https://jupyter.org/install.html

For Google Colab:- Just type Google Colab in any Search Engine and click on the Google Colab link(Upload  Code File in Your Google Drive Account and make sure the Path is correct according to your account where you have Uploaded).


# Algorithm Used:-
Random Forest :- is a classification algorithm that is comprised of many Decision Trees. Each tree has nodes with conditions, which define the final decision based on the highest value.

The Random Forest algorithm for fraud detection and prevention has two cardinal factors that make it good at predicting things. The first one is randomness, meaning that the rows and columns of data are chosen randomly from the dataset and fit into different Decision Trees. Say Tree Number 1 receives the first 1,000 rows, Tree Number 2 receives Rows 4,000 to 5,000, and the Tree Number 3 has Rows 8,000 to 9,000.

The second factor is diversity, meaning that there’s a forest of trees that contribute to the final decision instead of just one decision tree. The biggest advantage here is that this diversity decreases the chance of model overfitting, while the bias remains the same.


# Contributors
